import streamlit as st
from openai import OpenAI
import pandas as pd

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
data = pd.read_csv("/mnt/data/cj_data_final.csv", encoding="cp949").drop_duplicates()

# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": """
ë„ˆëŠ” ì²­ì£¼ ë¬¸í™”ìœ ì‚°ì„ ê°ì„±ì ìœ¼ë¡œ ì†Œê°œí•˜ëŠ” ê´€ê´‘ ê°€ì´ë“œ ì±—ë´‡ì´ì•¼.

[ì„¤ëª… ìˆœì„œ]
1. ì²­ì£¼ì˜ ì˜¤ëŠ˜ ë‚ ì”¨ì™€ ì—¬í–‰ íŒì„ ì•ˆë‚´í•´ì¤˜ â˜€ï¸â˜”
2. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê° ê´€ê´‘ì§€ë¥¼ ì•„ë˜ ìˆœì„œë¡œ ì†Œê°œí•´ì¤˜:
   â€¢ ê´€ê´‘ì§€ ì´ë¦„ ê°•ì¡° + ì´ëª¨ì§€ ì‚¬ìš© (ì˜ˆ: ğŸ›ï¸ ì •ë¶ë™ í† ì„±)
   â€¢ ì—­ì‚¬, ì˜ë¯¸, íŠ¹ì§•, ìì—° ë¶„ìœ„ê¸°, ì—¬í–‰ íŒ í¬í•¨
   â€¢ ë¬¸ë‹¨ë§ˆë‹¤ ì¤„ë°”ê¿ˆ, ê°ì„±ì  í‘œí˜„, ì—¬í–‰ì ì…ì¥ì—ì„œ ë§í•´ì¤˜
3. í•´ë‹¹ ê´€ê´‘ì§€ ì£¼ë³€ì˜ ì¹´í˜ëŠ” ì‹œìŠ¤í…œ(CSV)ì„ ê¸°ë°˜ìœ¼ë¡œ ì†Œê°œí•´ì¤˜.
   - ì¹´í˜ ì´ë¦„, í‰ì , ë¦¬ë·° ìš”ì•½ì„ ì˜ˆì˜ê²Œ í’€ì–´ì„œ ë³´ì—¬ì¤˜ â˜•
4. ë§Œì•½ CSVì— ì—†ëŠ” ê´€ê´‘ì§€ë©´ GPTê°€ ì§ì ‘ ì„¤ëª…í•´ë„ ê´œì°®ì•„!
"""
        }
    ]

st.title("ì²­ì£¼ ë¬¸í™” ì±—ë´‡ âœ¨")

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for msg in st.session_state.messages[1:]:
    if msg["role"] == "user":
        st.markdown(f"<div style='text-align: right; background-color: #dcf8c6; border-radius: 10px; padding: 8px; margin: 5px 0;'>{msg['content']}</div>", unsafe_allow_html=True)
    elif msg["role"] == "assistant":
        st.markdown(f"<div style='text-align: left; background-color: #ffffff; border-radius: 10px; padding: 8px; margin: 5px 0;'>{msg['content']}</div>", unsafe_allow_html=True)

st.divider()

# ì‚¬ìš©ì ì…ë ¥ì°½
user_input = st.text_input("ê¶ê¸ˆí•œ ì²­ì£¼ì˜ ê´€ê´‘ì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”! (ì˜ˆ: ì²­ë‚¨ëŒ€, ë¬¸ì˜ë¬¸í™”ì¬ë‹¨ì§€)")

# ì¹´í˜ í¬ë§· í•¨ìˆ˜
def format_cafes(cafes_df):
    if cafes_df.empty:
        return "âŒ ì£¼ë³€ ì¹´í˜ ì •ë³´ê°€ ì—†ì–´ìš”. ëŒ€ì‹  ê°€ê¹Œìš´ ê³³ì„ ì°¾ì•„ë³´ëŠ” ê±´ ì–´ë•Œìš”?"

    result = ["â˜• **ì£¼ë³€ ì¶”ì²œ ì¹´í˜ TOP 3**\n"]
    for i, row in enumerate(cafes_df.itertuples(), 1):
        stars = f"â­ {row.c_value}"
        cafe_block = f"{i}ï¸âƒ£ **{row.c_name}** ({stars})  \nâ€œ{row.c_review}â€"
        result.append(cafe_block)

    return "\n\n".join(result)

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ë³´ë‚´ê¸°") and user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("ì²­ì£¼ì˜ ì•„ë¦„ë‹¤ì›€ì„ ì •ë¦¬ ì¤‘ì´ì—ìš”..."):
        places = [p.strip() for p in user_input.split(',')]
        response_blocks = []

        # ë‚ ì”¨ ì†Œê°œ
        weather_intro = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì²­ì£¼ ë¬¸í™”ê´€ê´‘ ê°€ì´ë“œì•¼. ì˜¤ëŠ˜ ì²­ì£¼ì˜ ë‚ ì”¨ë¥¼ ì—¬í–‰ìì—ê²Œ ì†Œê°œí•´ì¤˜. ì˜·ì°¨ë¦¼, ìš°ì‚° íŒë„ í•¨ê»˜."}
            ]
        ).choices[0].message.content
        response_blocks.append(f"ğŸŒ¤ï¸ {weather_intro}")

        # ê´€ê´‘ì§€ë³„ ì„¤ëª… + ì¹´í˜ ë§¤ì¹­
        for place in places:
            matched = data[data['t_name'].str.contains(place, na=False)]

            # GPTì—ê²Œ ê´€ê´‘ì§€ ì„¤ëª… ìƒì„± ìš”ì²­
            gpt_place_response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì²­ì£¼ ë¬¸í™”ìœ ì‚°ì„ ê°ì„±ì ìœ¼ë¡œ ì†Œê°œí•˜ëŠ” ê´€ê´‘ ê°€ì´ë“œì•¼."},
                    {"role": "user", "content": f"{place}ì— ëŒ€í•´ ê°ì„±ì ì´ê³  ì—­ì‚¬ì ì¸ ì„¤ëª…ì„ í•´ì¤˜. ì´ëª¨ì§€ì™€ ì¤„ë°”ê¿ˆë„ ì ì ˆíˆ ì¨ì¤˜."}
                ]
            ).choices[0].message.content

            # ì¹´í˜ ì •ë³´
            if not matched.empty:
                cafes = matched[['c_name', 'c_value', 'c_review']].drop_duplicates().head(3)
                cafe_info = format_cafes(cafes)
            else:
                cafe_info = "\n\nâ— CSVì—ì„œ í•´ë‹¹ ê´€ê´‘ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´. ê·¼ì²˜ ì¹´í˜ëŠ” GPTê°€ ì„ì˜ë¡œ ì¶”ì²œí•  ìˆ˜ ìˆì–´ìš”!"

            # ì¡°í•©
            full_block = f"---\n\n{gpt_place_response}\n\n{cafe_info}"
            response_blocks.append(full_block)

        final_response = "\n\n".join(response_blocks)
        st.session_state.messages.append({"role": "assistant", "content": final_response})
